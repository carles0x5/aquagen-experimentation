{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Modify sys.path \n",
    "project_root = '/Users/carlesferreres/Desktop/Carles/Empresas/KOA/Repos/aquagen-experimentation/'\n",
    "os.chdir(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model config\n",
    "exp_id = 'acc1'\n",
    "model_name = 'nn_model_acc1_20240512.keras'\n",
    "dir = f'data/input_data/exp_{exp_id}'\n",
    "\n",
    "retrain = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_test = pd.read_csv(os.path.join(dir, 'X_test.csv'))\n",
    "y_test = pd.read_csv(os.path.join(dir, 'y_test.csv'))['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read model\n",
    "model = keras.models.load_model(os.path.join('models', model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "if retrain:\n",
    "    X_train = pd.read_csv(os.path.join(dir, 'X_train.csv'))\n",
    "    y_train = pd.read_csv(os.path.join(dir, 'y_train.csv'))['Class']\n",
    "    model.fit(X_train, y_train, epochs=200, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "True     169\n",
       "False     44\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test set distribution\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "AUC-PRC: 0.9518323\n",
      "ROC-AUC: 0.8938946\n"
     ]
    }
   ],
   "source": [
    "# Make predictions and evaluate main metrics\n",
    "y_pred = model.predict(X_test)\n",
    "auc_prc = keras.metrics.AUC(curve='PR', name='auc_prc')(y_test, y_pred) \n",
    "roc_auc = keras.metrics.AUC(name='roc_auc')(y_test, y_pred) \n",
    "\n",
    "print(\"AUC-PRC:\", auc_prc.numpy())\n",
    "print(\"ROC-AUC:\", roc_auc.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>false</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>false</th>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true</th>\n",
       "      <td>8</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             predicted     \n",
       "                 false true\n",
       "actual false        34   10\n",
       "       true          8  161"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate confusion matrix\n",
    "threshold = 0.5\n",
    "y_pred_rounded = tf.cast(tf.greater(y_pred, threshold), tf.float32)\n",
    "\n",
    "cm = tf.math.confusion_matrix(y_test, y_pred_rounded, num_classes=2)\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     columns=['false', 'true'],\n",
    "                     index=['false', 'true'])\n",
    "cm_df.columns = pd.MultiIndex.from_product([['predicted'], cm_df.columns])\n",
    "cm_df.index = pd.MultiIndex.from_product([['actual'], cm_df.index])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tn, fp, fn, tp values:\n",
    "TN = cm[0, 0].numpy()\n",
    "FP = cm[0, 1].numpy()\n",
    "FN = cm[1, 0].numpy()\n",
    "TP = cm[1, 1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate test metrics\n",
    "acc = 100*(TP+TN)/(TP+TN+FP+FN)\n",
    "precision = 100*TP/(TP+FP)\n",
    "recall = 100*TP/(TP+FN)\n",
    "fallout = 100*FP/(TN+FP)\n",
    "_for = 100*FN/(TN+FN)\n",
    "tnr = 100 - _for\n",
    "balanced_acc = (tnr + recall)/2\n",
    "f1 = 2*(precision*recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall model accuracy is 91.55%\n",
      "The overall model balanced accuracy is 88.11%\n"
     ]
    }
   ],
   "source": [
    "print(f'The overall model accuracy is {acc:.2f}%')\n",
    "print(f'The overall model balanced accuracy is {balanced_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given that there is a pathogen in the sample, the model is 95.27% likely to detect it.\n",
      "Given that there is no pathogen in the sample, the model is 22.73% likely to wrongly detect it.\n"
     ]
    }
   ],
   "source": [
    "print(f'Given that there is a pathogen in the sample, the model is {recall:.2f}% likely to detect it.')\n",
    "print(f'Given that there is no pathogen in the sample, the model is {fallout:.2f}% likely to wrongly detect it.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given that the model gave a positive result (pathogen), the sample is 94.15% likely to have a pathogen.\n",
      "Given that the model gave a negative result (no pathogen), the sample is still 19.05% likely to have a pathogen.\n"
     ]
    }
   ],
   "source": [
    "print(f'Given that the model gave a positive result (pathogen), the sample is {precision:.2f}% likely to have a pathogen.')\n",
    "print(f'Given that the model gave a negative result (no pathogen), the sample is still {_for:.2f}% likely to have a pathogen.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
