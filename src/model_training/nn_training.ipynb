{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "import keras\n",
    "from keras_tuner import BayesianOptimization, HyperParameters, HyperModel, Objective\n",
    "import tensorflow as tf\n",
    "\n",
    "# Modify sys.path \n",
    "project_root = '/Users/carlesferreres/Desktop/Carles/Empresas/KOA/Repos/aquagen-experimentation/'\n",
    "os.chdir(project_root)\n",
    "\n",
    "from src.utils.google_drive import GoogleDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_CONFIG_PATH = os.getenv('EXPERIMENT_CONFIG_PATH')\n",
    "with open(EXPERIMENT_CONFIG_PATH) as json_file:\n",
    "    exp_config = json.load(json_file)\n",
    "\n",
    "folder_id = exp_config.get('data').get('source').get('folder_id')\n",
    "filename = exp_config.get('data').get('source').get('filename')\n",
    "first_date = exp_config.get('training').get('first_date')\n",
    "feature_columns = exp_config.get('training').get('feature_columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "gdw = GoogleDrive()\n",
    "file = gdw.read_file(folder_id, filename)\n",
    "df = pd.read_excel(file, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform dates\n",
    "df['ExperimentDate'] = df.ExperimentDate.str[:10]\n",
    "df['ExperimentDate'] = pd.to_datetime(df['ExperimentDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter valid samples and fix data\n",
    "df = df[df.ExperimentDate >= pd.to_datetime(first_date)]\n",
    "df = df[df.InputType == 'Pathogen']\n",
    "df.fillna(-1, inplace=True)\n",
    "df['Class'] = df.InputName.str.lower() != 'control'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "True     822\n",
      "False    194\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# View classes distribution\n",
    "print(df['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize / Standardize\n",
    "scaler = StandardScaler()\n",
    "# scaler = Normalizer()\n",
    "df[feature_columns] = scaler.fit_transform(df[feature_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X = df[feature_columns]\n",
    "y = df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model builder function\n",
    "class MyHyperModel(HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=hp.Int('units', min_value=32, max_value=512, step=32), \n",
    "                        activation='relu', \n",
    "                        input_dim=X_train.shape[1]))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "\n",
    "        for _ in range(hp.Int('num_layers', 1, 6)):\n",
    "            model.add(Dense(units=hp.Int('units', min_value=32, max_value=512, step=32), \n",
    "                            activation='relu'))\n",
    "            model.add(Dropout(rate=hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        optimizer = Adam(learning_rate=hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='log'))  \n",
    "        model.compile(optimizer=optimizer, \n",
    "                      loss=keras.losses.BinaryCrossentropy(), \n",
    "                      metrics=[keras.metrics.AUC(curve='PR', name='auc_prc')])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping and model checkpoint callbacks\n",
    "callbacks = [\n",
    "    # keras.callbacks.ModelCheckpoint(filepath=\"model_at_epoch_{epoch}.keras\")\n",
    "    # keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 01m 02s]\n",
      "val_auc_prc: 0.9909807443618774\n",
      "\n",
      "Best val_auc_prc So Far: 0.9936025142669678\n",
      "Total elapsed time: 00h 58m 59s\n"
     ]
    }
   ],
   "source": [
    "# Perform hyperparameter tuning with Bayesian optimization\n",
    "tuner = BayesianOptimization(\n",
    "    MyHyperModel(),\n",
    "    objective=Objective('val_auc_prc', 'max'),\n",
    "    max_trials=100,\n",
    "    max_retries_per_trial=3,\n",
    "    max_consecutive_failed_trials=8,\n",
    "    seed=42,\n",
    "    directory='tuning-dir',\n",
    "    project_name='aquagen-training'\n",
    ")\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=200, validation_split=0.2, callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlesferreres/Desktop/Carles/Empresas/KOA/Repos/aquagen-experimentation/.venv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'units': 32, 'dropout_rate': 0.1, 'num_layers': 6, 'learning_rate': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlesferreres/Desktop/Carles/Empresas/KOA/Repos/aquagen-experimentation/.venv/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 34 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(1)[0]\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "print(best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with the best hyperparameters\n",
    "# final_model = best_model.build(input_shape=X_train.shape)\n",
    "# final_model.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "True     167\n",
       "False     37\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test set distribution\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fd585cafdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "AUC-PRC: 0.97872174\n",
      "ROC-AUC: 0.92442137\n"
     ]
    }
   ],
   "source": [
    "# Make predictions and evaluate main metrics\n",
    "y_pred = best_model.predict(X_test)\n",
    "auc_prc = keras.metrics.AUC(curve='PR', name='auc_prc')(y_test, y_pred) \n",
    "roc_auc = keras.metrics.AUC(name='roc_auc')(y_test, y_pred) \n",
    "\n",
    "print(\"AUC-PRC:\", auc_prc.numpy())\n",
    "print(\"ROC-AUC:\", roc_auc.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>false</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>false</th>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true</th>\n",
       "      <td>27</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             predicted     \n",
       "                 false true\n",
       "actual false        32    5\n",
       "       true         27  140"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate confusion matrix\n",
    "threshold = tf.math.reduce_mean(y_pred)\n",
    "y_pred_rounded = tf.cast(tf.greater(y_pred, threshold), tf.float32)\n",
    "\n",
    "cm = tf.math.confusion_matrix(y_test, y_pred_rounded, num_classes=2)\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     columns=['false', 'true'],\n",
    "                     index=['false', 'true'])\n",
    "cm_df.columns = pd.MultiIndex.from_product([['predicted'], cm_df.columns])\n",
    "cm_df.index = pd.MultiIndex.from_product([['actual'], cm_df.index])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tn, fp, fn, tp values:\n",
    "TN = cm[0, 0].numpy()\n",
    "FP = cm[0, 1].numpy()\n",
    "FN = cm[1, 0].numpy()\n",
    "TP = cm[1, 1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.74358974358975"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate test metrics\n",
    "acc = 100*(TP+TN)/(TP+TN+FP+FN)\n",
    "precision = 100*TP/(TP+FP)\n",
    "recall = 100*TP/(TP+FN)\n",
    "fallout = 100*FP/(TN+FP)\n",
    "_for = 100*FN/(TN+FN)\n",
    "tnr = 100 - _for\n",
    "balanced_acc = (tnr + recall)/2\n",
    "f1 = 2*(precision*recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall model accuracy is 84.31%\n",
      "The overall model balanced accuracy is 69.03%\n"
     ]
    }
   ],
   "source": [
    "print(f'The overall model accuracy is {acc:.2f}%')\n",
    "print(f'The overall model balanced accuracy is {balanced_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given that there is a pathogen in the sample, the model is 83.83% likely to detect it.\n",
      "Given that there is no pathogen in the sample, the model is 13.51% likely to wrongly detect it.\n"
     ]
    }
   ],
   "source": [
    "print(f'Given that there is a pathogen in the sample, the model is {recall:.2f}% likely to detect it.')\n",
    "print(f'Given that there is no pathogen in the sample, the model is {fallout:.2f}% likely to wrongly detect it.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given that the model gave a positive result (pathogen), the sample is 96.55% likely to have a pathogen.\n",
      "Given that the model gave a negative result (no pathogen), the sample is still 45.76% likely to have a pathogen.\n"
     ]
    }
   ],
   "source": [
    "print(f'Given that the model gave a positive result (pathogen), the sample is {precision:.2f}% likely to have a pathogen.')\n",
    "print(f'Given that the model gave a negative result (no pathogen), the sample is still {_for:.2f}% likely to have a pathogen.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
